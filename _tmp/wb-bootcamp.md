# 微博新兵训练营（课程）

- 基础部分
    - 研发环境与工具体系介绍
    - 分布式缓存架构基础
    - 海量数据存储架构基础
    - 技术框架与组件使用
    - 代码优雅及问题排查工具与方法
- 业务实战部分
    - 微博信息流业务架构
    - 直播与通讯业务架构
    - 大数据与推荐业务架构
    - 微博安全攻防策略实战

# 研发环境与工具体系介绍

<https://weibo.com/ttarticle/p/show?id=2309404017738262668485&mod=zwenzhang>

- 以下均为 todo

idea plugins
    maven helper
        <https://www.codelast.com/%E5%8E%9F%E5%88%9B-%E5%9C%A8intellij-idea%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%8F%92%E4%BB%B6%E6%9F%A5%E7%9C%8Bmaven-conflict/>
        <https://plugins.jetbrains.com/plugin/7179-maven-helper>
vim
    https://github.com/dofy/learn-vim
cmd
    coreutil
    used

# 分布式缓存架构基础

<https://weibo.com/ttarticle/p/show?id=2309404022116222639373&mod=zwenzhang>

- 根据业务场景，通常缓存有以下几种使用方式
    - 懒汉式(读时触发)：写入DB后, 然后把相关的数据也写入Cache
    - 饥饿式(写时触发)：先查询DB里的数据, 然后把相关的数据写入Cache
    - 定期刷新：适合周期性的跑数据的任务，或者列表型的数据，而且不要求绝对实时性
    （不是很理解）
- 分类
    - 应用内缓存：Map（简单的数据结构）、EH Cache（Java 第三方库）
    - 缓存组件：Memcached、Redis
- Memcached
    - 分布式
    - 高性能 k-v 存储
    - 协议简单：简单文本协议、二进制协议
    - 支持数据过期
    - LRU 踢出算法
    - 多线程
    - slab 内存管理（重点：slab！）
- Redis
    - 分布式
    - 高性能 k-v 存储
    - 丰富的数据结构：string, list, hash, set, zset, hypeloglog(?)
    - 支持数据过期：主动过期 + 惰性过期
    - 支持多种 LRU 策略：volatile-lru, volatile-ttl
    - 内存管理：tcmaloc, jemalloc
    - 内存存储 + 磁盘持久化：rdb, aof
    - 支持主从复制
    - 单线程
    - 微微博使用的是内部定制的redis版本
        - 支持热升级
        - 基于 aof 的增量复制
        - 新数据类型 longset 和 bloomfilter 等
        - 但在微博的场景下，Redis 更多被用存储和计数器场景
        - 缓存主要以 memcached 为主
- 挑战
    - 百万级 QPS 的资源调用 (高并发)
    - 99.99% 的可用性 (高可用)
    - 毫秒级的核心请求响应时间 (高性能)
- 分布式缓存实现
    - 数据分片
        把数据分散到多个实例中
        - 规则
            - 区间分片？
            - hash 分片
            - slot 分片（和 hash 分片的区别？）
        - hash 分片的方式
            - 静态哈希（取模求余）
                - 优：算法简单（简单小规模的业务实现，可以简单地部署、替换、修复）
                - 劣：加减节点时，震荡厉害，命中率下降严重
            - 一致性哈希
                - 优：加减节点时，震荡较小，保持较高命中率
                - 劣：自动 rehash 的场景下，会产生数据不一致的问题
                    （同一份数据的请求在不同的节点漂移）
        - 数据分片的方式
            - 客户端实现：Memcached, Redis 2.x
                - 优：简单，容易实现
                - 劣：扩缩容需要重新上线，手动数据迁移
            - proxy 实现：twemproxy(?), codis(?)， 微博内部实现了 CacheService(?)
                通过引入一层代理，将数据分片策略放在代理层实现，客户端通过代理来访问数据
                - 优：逻辑在 proxy 实现，客户端使用简单，支持多语言
                - 劣：数据访问多一次跳转，有一定性能损耗
            - 服务端实现：Redis 3.x, cassandra(?)
                由于缓存组件本身，实现数据分片机制
                - 优：扩缩容方便，自动数据迁移
                - 劣：数据存储和分布式逻辑耦合在一起，服务端复杂
    - 可用性
        线上使用过程中，如果出现某些缓存实例不可用，大量请求穿透会给DB带来巨大的压力，极端情况会导致雪崩场景。
        - 采用主从架构（Master/Slave）在原有单层缓存的结构下，
            增加一层 Slave，来保证某个 Master 节点不宕机
    - 拓展性
        - 主从结构已经能很好地满足大多数业务场景
        - 但在微博这种存在突发热点引起流量骤增的业务场景下，仍然存在一定的问题
            - 因为不能方便地进行横向拓展，如果在原有的缓存中增加新节点，就需要涉及数据迁移工作。
        - 为了解决横向拓展的问题，增加 L1 Cache，实现多级缓存，
            L1 Cache 一般小于 Master 的容量，其中的数据热度更高，
            而且 L1 Cache 可以有多组
        - 但是增加 L1 Cache 后，Master/Slave 的访问量会小很多，出现数据变冷的情况（数据太旧？）
            为了改善该情况，吧 Master/Slave 在逻辑上也作为 L1 Cache 中的一组，就保证了其热度
            （详细看原文章的插图！）
- 缓存设计实践
    - Memcached Multiget-Hole（multiget 黑洞）
        - Memcached 才用数据分方式部署的情况下，对 multiget 命令来说，部署更多的节点，并不能提升承载量
            甚至出现节点越多，multiget 效率反而更低的情况，这就是 multiget 黑洞
        - 因为执行 multiget 命令时，会访问每一个节点，通常 SLA 取决于最慢最坏的节点，
            增加的节点越多，出问题的概率越大，客户端处理压力也会增大。
        - 数据分片时，推荐 4~8 个节点。
        - 解决方法（可供参考）：
            - 使用多副本的方式扩容（TODO：多副本是什么方式？），增加 multiget 的承载量
            - 通过业务层面来控制，multiget 的 keys 尽可能放在同一个节点上，但具体实施时，较难操作，可行性不是很高。
    - 反向 Cache
        - 指的是将不存在的 key 放在缓存中，就是在缓存中存一个空值。（？？）
            某些场景下，比如微博维度的技术场景，才用 cache + DB 的存储方式，
            由于大多数的微博并不存在转发、评论的计数，会出现由于大量访问不存在计数的 mid，
            导致 DB 压力居高不下的情况。
        - 通过在 cache 中存一个 null 值，可以减少对 DB 的穿透。但是：
            - 如果每次都是不同的 mid，缓存效果可能不明显
            - 需要更多的缓存容量
    - 缓存 Fail-Fast（快速失败）
        - 当缓存层某个节点出现故障时，导致请求持续穿透到存储层，
            是请求响应时间长（等到读写故障缓存节点超时），并且存储层负载居高不下。
        - 这时需要在缓存时，考虑「快速失败机制」：
            - 当出现故障节点时，标志故障节点为不可用节点，
                （策略举例：连续 N 次请求都出现了超时，标志 M 时间段内，该节点不可用）
                读写不可用节点时快速返回。
        - 用以解决响应时间长的问题，保证 SLA
    - 缓存无过期 Cache is Storage
        - 指缓存中存储全量数据，不存在数据穿透的情况
        - 相比于 Cache + DB 的访问模型，使用内存存储简单可靠，但内存成本较高
        - 选择「内存缓存」还是「内存存储」，结合具体业务场景权衡，
            比如单纯为解决 Dog-Pile Effect 而采用内存村春的话，内存成本可能无法接受。
        - 它适合，总体数据量很小，但是访问量巨大的业务场景，例如微博应用
    - Dog-Pile Effect（狗桩效应）
        - 指由于极热访问的缓存数据失效，大量请求发现没有缓存，进而穿透到 DB，
            导致数据库 load 瞬间飚高甚至宕机
        - 典型的并发访问穿透问题，理想情况下，缓存失效时对 DB 应该只有一次穿透。
            - 可以考虑使用基于 MC 的分布式锁来控制，不过实践比较繁琐
            - 通常在代码层进行控制，就可以得到很好的效果（TODO：具体是怎么控制？？？）
    - 极热点数据（场景）
        - 微博突发事件发生时（鹿晗女朋友、文章出轨、范冰冰「我们」），
            流量出现爆发式增长，大量的热点集中访问，导致某个缓存资源遇到性能瓶颈（明星数据所在的资源端口），
            最终接口响应变慢影响正常服务
        - 为了应对该问题，在前端使用 local cache，命中率可能不高，性能提升不明显；
            业务场景下可以考虑引入 L1 结构，通过部署多组小容量的 L1 Cache 来应对突发性的访问量增长
    - 避免雪崩
        - 雪崩效应：由于缓存服务器宕机等原因，导致命中率降低，大量的请求穿透到数据库，
            导致数据库被冲垮，业务系统出现故障，服务很难在短时间内恢复
        - 避免方法：
            - 缓存高可用
                避免单点故障，保证缓存高命中率
            - 降级和流控
                故障期间，通过降级非核心功能来保证核心功能可用性
                通过拒掉部分请求保证有部分请求正常响应
                （服务端随机丢弃请求，客户端随机时间重试、熔断？）
            - 清楚后端资源容量
                更好地预测风险点，提前做好准备
                即使出现问题，也便于更好地流控（准备好应急方案）
    - 数据一致性
        - CAP 理论：
            consistence 一致性
                等同于所有节点访问同一份最新的数据副本
            availability 可用性（高可用）
                每次请求都能获取到非错的响应——但不保证获取的数据为最新数据
            partition tolerance 分区容错性（可拓展性）
                以实际效果而言，分区相当于对通信的时限要求。
                系统如果不能再时限内达成数据一致性，就意味着发生了分区的情况，
                必须就当前操作，在 C 和 A 之间做出选择
        - 根据 CAP 理论，三者只能取其二，无法全部保证。
        - 分布式缓存，通常要保证可用性（A）和可拓展性（分区容错性 P），
            并这种采用数据「最终一致性」：
            - Master/Slave 一致
            - Cache 和 Storage 一致
            - 业务各维度缓存数据一致
    - 缓存容量规划
        考虑方面：
        - 请求量（query，还有 QPS）
        - 命中率：预热（提早将一些热点数据写入缓存），防止雪崩
        - 网络带宽：网卡、交换机
        - 存储容量：预估存储大小、过期策略、剔除率
        - 连接数
- 微博缓存中间件 CacheService
    （中间件的架构，详见原文的插图）
    - 随着微博业务数据增长，缓存集群的规模越来越大，直接使用裸缓存资源的方式，运维管理很不方便：
        - 缓存资源的变更复杂度高
            节点变更、扩缩容，需要业务方变更配置，然后重新上线，
            而且资源变更过程中，业务方密切关注缓存的服务状况
        - 高可用策略无法复用
            微博平台用 Java，其 client 定制了保证缓存高可用性的多级缓存访问策略，
            公司其它部门使用非 Java 的编程语言，则无法复用该 client
        - 运维复杂度高
            缺少简单友好的统一运维管理平台，来负责缓存资源的申请、分配、部署、变更、回收等操作。
            运维操作没有实现全界面话，且自动化程度不高。
        - 缺少 SLA（指标保证）
            缓存资源异常导致业务出现问题时，缺少业务缓存 SLA 指标的监控和处理，
            更多地依赖用户投诉然后才能执行后续的运维处理，整个反馈过程周期比较长，对业务影响大。
    - 框架组件
        - 代理层：代理业务端的请求，基于设定的路由规则转发到后端的 Cache 资源，服务本身是无状态的。
            支持配置服务化、多级 cache 访问策略、集群建数据复制、S4LRU（TODO: what is?）等特性。
        - 资源层：实际的数据存储引擎，初期支持 memcached，后续拓展了 Redis、SSDCache 组件，
            其中 SSDCache 是为了降低服务成本，内部开发的基于 SSD 的存储组件，
            用于缓存结余 memory 和 DB 之间的 warm 数据
        - 客户端：业务只需要简单配置所使用的服务池名 group 和业务标识的 namespace 即可使用
            Java 业务方：通过配置中心获取可访问的 proxy 节点
            PHP 业务方：本地 proxy 节点 or DNS（通过改 Host 对应的 IP，来切换资源）
        - 集群管理系统 ClusterManager：管理缓存的整个生命周期，包括缓存资源的申请、上线、变更、下线等；
            管理急群众所有组件的运行状态及业务的 SLA 指标，出现异常时，自动触发运维操作。
    - 更多请参考：[从优化性能到应对峰值流量：微博缓存服务化的设计与实践](https://weibo.com/ttarticle/p/show?id=2309404013728432540615)

## 从优化性能到应对峰值流量：微博缓存服务化的设计与实践

<https://weibo.com/ttarticle/p/show?id=2309404013728432540615>

- Main-HA 双层架构
    - HA: High Available 高可用性集群，一般有两个及以上节点，分为活动节点和备用节点。
        活动节点：正在执行任务的节点。备用节点，是活动节点的备份。
        备份节点检测到活动节点出现问题时，立即激活为「活动节点」来执行任务，
        以保证业务不中断或短暂中断。
    - 访问后端的缓存资源时，先访问 Main 层，如果 miss 继续访问 HA 层，
        从而在获得更高的命中率的同时，即使 Main 节点不可用，也可以保证缓存命中率，减少 DB 压力
    - 对业务资源进一步分拆，每一种核心数据都分拆到独立的端口。
        根据不同的 __访问频率、容量__ 进行缓存搭配部署。
    - 在海量业务数据的冲刷下，前端使用 local-cache 命中率不高，性能提升不明显，
        所以去掉了 local-cache 层
    - 随着业务访问量进一步增加，突发事件爆发式传播，Main-HA 结构，也有问题。
        主要是很多缓存节点的带宽代码，Memcache 的 CPU 较高，Memcache 响应变慢。
    - 发现主要是大量热数据集中访问导致业务过载，单端口不能承载热数据的访问（明星发博所在的端口）
        所以引入了 __L1 (Cache) 结构__
    - 通过部署 3~4 组以上的小容量 L1 缓存，每个 L1 组等价存储热数据，来满足业务要求。
- 演进过程
    - 裸缓存资源，通过 Main-HA 双层结构，消除单点（故障）问题
    - 通过热数据的多 L1 副本，可以用较低的成本应对高峰、突发流量
    - L1s-Main-HA 三层缓存结构消除了缓存曾出现的带宽和 CPU 过载的情况，
        使整个系统的可读性、可用性有很大提高
    - 但是服务的可管理型方面，依然存在提升空间，需要将缓存服务化，以提高 __复用性__
        （非 Java 语言的服务，也可以调用）
- 缓存服务 设计与实践
    - 背景：随着业务发展，微博缓存的访问量 + 容量 都非常大。
        线上有数千个缓存节点，都需要业务前端去配置，导致缓存配置文件很大很复杂。
    - 亟待解决的问题：
        - 如果需要缓存节点扩容或切换，需要运维通知业务方，修改配置，然后重启，过程长，影响服务稳定性。
        - 平台的 Java 定制了 Java Memcache 魂村层来访问三层缓存结构，内置了许多访问策略。
            如果其他非 Java 的部门想复用，就很麻烦。
        - 可运维性不足，基于 IP、端口运维复杂性比较高。
            如果线上一台机器宕机，这个机器上部署了哪些端口，对应了哪些业务调用，
            没法简单直观地查询，然后管理。
    - 缓存服务化的过程：
        对 Memcache 缓存引入 proxy 层，
            基于 Twitter 的 [Twemproxy](https://github.com/twitter/twemproxy)
            简介 <http://www.cnblogs.com/gomysql/p/4413922.html>
        引入 cluster，并内嵌 Memcache Cluster 访问策略，
            包括三层的一些更新、读取、miss 后的穿透、回写等
        通过单进程单端口来对多个业务进行访问，不同业务通过 namespace prefix 区分
        cacheProxy 引入 LRU，减少热点数据的穿透
            简化业务前端的配置，简化开发，开发人员只需要知道 cacheProxy 的 IP 和端口
            即可实现对后端各种业务的多层缓存的访问
            （缓存服务的服务治理）
- 接入配置中心
    把 cache 层接入配置中心 configServer（内部称为 vintage）
        实现 Memcache 缓存、cacheProxy 的动态注册和订阅，
        运维将 Memcache 资源的 IP:PORT、访问的 hash 方式、分布式策略等，
        也以配置的形式注册在配置中心
    cacheProxy 启动后，通过配置中心订阅资源的 IP:PORT 访问方式，
        正确连接并访问后端 Memcache 缓存资源
        而且自身也会注册到配置中心
    client 可以在配置中心订阅 cacheProxy 列表，选择最佳的节点来访问缓存
        运维可在线在配置中心管理 Memcache 资源，网络中断、宕机，
        需要启动新的 Memcache 节点，并添加到配置中心，
        以便资源快速生效，从而实现资源管理的 API 化、校本化
- 监控体系
    cacheProxy 和后端 Memcache 资源，纳入 Graphite 体系 <https://graphiteapp.org/>
        Docs <https://graphite.readthedocs.io/en/latest/overview.html>
    通过 logtailer <https://github.com/ParsePlatform/logtailer>
        将缓存的访问日志、内部状态推送到 Graphite 系统，
        用 dashboard 直接展现或者按需聚合后展现
- Web 化管理
    缓存层管理组件 clusterManager（内部称 captain），将 API 化、脚本化的管理，升级为界面化管理，
        运维通过 clusterManager 管理缓存的生命周期，包括申请、审核、变更、扩缩容、上下线等
- 监控与告警
    clusterManager 对缓存资源、cacheProxy 等进行状态探测和局和分析，
        监控缓存资源的 SLA，必要时监控报警
    整合 jpool（编排发布系统）、DSP（混合云管理平台）等系统
        实现了对 cacheProxy、Memcache 节点的一键部署和升级
- 开发工具
    对于 client 端，基于 Motan（微博开源 RPC 框架）扩展了 Memcache 协议（其它略）……
- 部署方式
    （该节最好看原文，不细记）
    - 集群内的扩缩：线上操作最多的是增减 L1 组或扩容 Main 层
        对于 L1，通常直接进行上下线资源，
            通过 captain（clusterManager）对配置中心的配置做变更即可生效
        对于 Main 层扩容，有两种方式
            1. 将新的 Main 层，作为 L1 上线，命中率达到要求后，
                再变更一次配置，去掉老的 main，使用新的 main
            2. 使用 main-elapse 策略：把老的 main 改成 main-elapse，
                main 层 miss 后，先访问 main_elapse 并返回，set 时对 main-elapse 做删除操作~
    - 集群的增减：增加新组件 updateServer，通过复制来实现
        - 为什么有集群上的增减？因为微博的访问存在时间上的规律性，午晚高峰
            （午 12:30 晚 10:30（早 9 点至晚 0 点），或时事热点（奥运、世界杯、节假日））
            流量有 30%~50% 的变化，需要新建 前端（机）+ 资源集群；
            所以提早 1~2 小时，在公有云部署资源服务，并预热数据，提供新集群给业务方使用，峰值过后再下线
        - 缓存集群：分为 master 集群、slave 集群
            数据读写（__这小节很重要__ 看原文！）
            Read: cacheProxy -> L1s-Main-HA
            Write: cacheProxy -> updateServer-master { os core -> AOF } -> L1s-Main-HA
                Master<->Salve Sync: updateServer-master -> updateServer-slave
            cacheProxy 和 updateServer 服务可以合二为一，变成一个进程
            LRU 省纪委 LS4LRU，线上数据分析，相同容量和过期时间，命中率总体进一步提升 5% ~ 7%
        - LS4LRU:
            - S4LRU：分为四个子 LRU，LRU0 ~ LRU3
                Key miss 或新写入一个 key 时，把 key 放到 LRU0，
                再被命中，则移到 LRU1，继续被命中，则移到 LRU2，直到 LRU 3；
                如果 LRU3 的数据太多了，需要 evict 数据，则把数据降到 LRU2 上，如此类推；
                有过期时间，如果发现过期就清理掉。
            - LS4LRU：在 S4LRU 基础上，增加一个分级的过期时间，
                每个 k-v 有两个过期时间 exp1（1 sec）和 exp2（3 sec）；
                LS4LRU 的缓存命中时，如果发现是 1s 内的数据，直接返回给客户端，
                    如果是 1~3s 内的数据，则先将数据返回给客户端，然后异步获取最新的数据并更新，
                    如果是 3s 以上的数据，则直接清理掉，然后走 key miss 的流程。

## 微博数据库那些事儿：3个变迁阶段背后的设计思想

- 作者：肖鹏，微博研发中心技术经理，负责微博数据 MySQL, Redis, HBase, Memcached
- 微博数据库变迁
    - 初创阶段：
        __数据库架构：1M/2S/1MB 结构__（TODO: 不懂，直接问问肖鹏）
        __按照读写分离设计，主库承担写，从库承担读__
        如果访问压力过大，通过扩容从库的数量，以获得 scale out 的能力
        - scale out 即 scale horizontally，横向拓展，向外拓展
            例如，向原有的服务，添加资源
        - scale up 即 scale vertically，纵向拓展，向上拓展
            例如，向原有的机器，添加 CPU、内存
    - 爆发阶段：
        - 首先通过高性能的硬件采购，对单机性能进行 scale up，先支撑住业务的高速发展，争取时间
        - 将业务进行垂直拆分，用户、关系、博文、转发、评论等功能模块分别独立存储
        - 在垂直拆分的基础上，对于一些语气会产生海量数据的业务模块，进行二次拆分
        - 逸闻
            - 直接购买 PCIe Flash 设备支撑核心业务
            - 初期 feed 系统重度依赖 MySQL
                2012 年春晚当前，MySQL 写入 QPS 曾经飙升到 3.5w（TODO：那是怎样一个峰值）
            - 高性能硬件价格比普通硬件昂贵许多，但是争取来的时间是宝贵的，
                不能因为初期上的性能问题，导致产品发生故障，以致用户流失，更得不偿失。
                在前期的爆发阶段，高丽投入资金解决问题，反而是最划算的。
        - 挑战用较低的成本存储数据
            - 拆分「索引」和「内容」
                索引所需存储空间较小，内容所需较大，其使用需求不尽相同，访问频次不同
            - 分别对索引和内容采用先 hash，再按照时间维度拆分的方式进行水平拆分
                尽量保障每张表的容量在可控范围之内，以保证查询的性能指标（分库分表）
            - 先通过「索引」获取所需内容的 id，再通过「内容库」获取实际的内容
                通过部署 memcached 来加速这个过程，虽然步骤变多（复杂）
            - 索引和内容，都分别拆分为很多端口，端口中再分了许多 DB，
                每个 DB 下的 table 先 hash 后按照时间维度进行拆分（例如：月/日？），
                这样后期遇到「容量、性能」瓶颈时，可以选择「归档」或调整部署架构，很灵活便利
                - 归档后，可以选择不同的硬件（硬盘、性能不同的机器）承担不同业务，提高利用率和成本
    - 沉淀阶段：
        经历过很多拆分改造，直接造成了规模成倍增长的状况，而业务高速增长之后，开始趋于稳定。
        着重「自动化」建设，将快速扩张期间积累的经验，用自动化工具实现。
        - 自动化：备份系统、监控系统、AutoDDL 系统、MHA 系统、巡检系统、慢查系统、maya 中间件系统。
        - 提高业务使用效率、降低沟通成本，重新开发 iDB 系统供数据库平台的用户使用。
            - 通过 iDB 系统，了解业务数据库的运行状态，直接提交对数据库的 DDL 修改需求，
                DBA 审核通过后，交由 Robot 自动线上执行，提高安全性和规范性。
        - 自动化分阶段：
            - 机器代替 __人工__：大规模的批量机械重复劳动交给程序实现，解决批量操作、重复性劳动的问题
            - 机器代理 __人__：替人进行一定的判断后，进行自我选择，彻底解放人力。
    - 小技巧
        - MySQL 的 __慢查询__ 是导致线上性能慢的罪魁祸首，
            但是很多时候并 __不是没有 index__，只是由于代码写得有问题，引起了 __隐式转换__ 等问题。
            在这种情况下，一般建议 __所有的 where 条件都加上双引号__，就可以直接消除隐式转换的可能性了，
            开发人员在写代码的时候也不用刻意去考虑到底是字符型还是 int 型。
- 数据库 设计与优化
    - MySQL、Redis、Memcached、HBase。2015 中间研发精力投入到 Redis
    - Redis 实践
        - 增加基于 pos 位同步功能
            Redis 2.4 同步一旦出现中断，就会重新将主库的数据「全部」传输到从库上，
            造成瞬时的网络带宽峰值；数据量较大的服务，从库恢复时间较长。
            所以借鉴 MySQL 的主从同步复制机制，将 Redis 的 AOF 改造为记录 pos 位，
            并让从库记录已同步的 pos 位开始进行重传，即使网络出现波动（后来 Redis 原生支持了）
        - 在线热升级
            使用初期，Redis 新功能不断添加，需要进行版本升级，
            为了不影响业务，每次升级都需要主库切换，造成运维上的挑战，于是考虑开发「热升级机制」
            通过动态加载 redislib.so 来实现版本的改变，
            不再需要进行主库切换，极大地提升了运维效率，降低了风险
        - 定制化改造
            在使用 Redis 后期，由于微博产品上技术类的需求非常多，
            专门开发了兼容 Redis 的 rediscounter，专门存储技术类数据，
            用 array 替换 hash table 极大地降低内存占用
            开发了基于 bloom filter 的 phantom 解决判断类场景需求
    - Redis 中间件
        - tribe
            2015 自研的 Redis 中间件 tribe 系统完成开发与上线。
            __tribe 采用有中心节点的 proxy 架构设计，通过 configServer 管理集群节点__，
            借鉴官方 __Redis Cluster 的 slot 分片__ 的设计思路来完成 __数据存储__，
            实现了 __路由、分片、自动迁移、fail over（失效备援）__ 等功能
            并预留了操作和监控的 API 接口，以便与自动化运维系统对接。
            （失效备援：系统备援能力的一种，当系统中其中一项设备失效而无法运作时，
                另一项设备即可自动接手原失效系统所执行的工作。）
            - 主要目的：解决自动迁移的问题
                Redis 内存使用呈现波动性变化，前一天 10%，今天可能 80%，
                这时人工迁移无法跟上业务的变化，如果恰巧碰到物理内存的瓶颈，就很麻烦，
                涉及业务重构数据的 hash 有可能导致故障。
            - 基于 slot 的动态迁移，首先对业务无感知，而且不需要整台服务器
                只需找到有可用内存的服务器，就可以将部分 slot 迁移过去，直接解决扩容迁移的问题，
                极大地提高服务器的利用率、降低成本
            - 路由功能，降低开发门槛，不需要将资源逻辑配置写到代码或前端配置文件中
                每次更改变更时，不再需要上线，提高开发效率，降低变更导致的故障风险
        - Databus
            - 将 MySQL 的数据，同步到其它数据库中（Redis, HBase）。
                可以基于 MySQL 的 binlog 将数据同步到其它异构的数据库中，支持自定义的业务逻辑。
            - Databus 的初衷是解决写 Redis 的问题，
                一些数据需要同时写到 MySQL 和 Redis 中，如果前端开启双写也可以解决，但是代码复杂；
                如果后端实现一个数据链路，会让代码更清晰，保障数据的最终一致性。
            - 后来在实际应用中，也承担了导入导出数据的功能。
        - 「反范式」的设计思路
            微博积累的数据库设计习惯，采用「反范式」的设计思路。
            - 预拆分：接到需求时，提前进行针对性的 __容量预估__，按照 __先垂直后水平__ 进行拆分，
                如果可以按照时间维度设计，就纳入 __归档机制__，对数据库进行 __分库分表__，解决容量存储问题
            - 引入消息队列：利用队列「一写多读」特性，或多队列来满足冗余数据的多份写入需求，
                仅能 __保障最终一致性__，可能出现数据延迟。
            - 引入接口层：通过不同业务模块的接口，将数据汇总之后，再返回应用层，降低应用层开发的编码复杂度
    - Q & A
        - 不小心执行 drop table 操作
            （delete 删除单行，truncate 删除表数据，drop 把表定义也删除掉）
            后续规范：无论多紧急的表删除需求，都必须进行 24h 的「冷却」：
            - 执行 rename table 操作，将 table_name 改为 table_name_will_drop
            - 等待 24h 后，再执行 drop 操作
        - 微博爆发性发展阶段，对索引和内容进行 hash，按照时间维度分库分表，展开讲讲
            - 预估一年大概的数据的数量级别，计算需要拆分的表的数目，
                尽量将每个表控制在 3 千万行记录以内（实际上计划赶不上变化）。
            - 根据博文 id 将所有产生的博文分到 1024 张表中
                （博文 id 涉及 uuid 全局发号器，暂不展开）
            - 微博大部分用户产生的内容都会和时间挂钩，假设每月建表，每月产生 1024 张表，
                如果 DB 出现瓶颈，可以根据时间维度解决，
                可以将 2010 年的所有表都迁移到其它数据库中
                （不是很理解，具体效果是旧的内容放到更深的架构层级里？）。
        - LinkedIn 多年前出过一个类似 databus 的项目，
            后续也有开源项目支持了 MySQL 到 HBase、ES 等的数据同步，微博的项目会开源么？
            - 异构数据的同步，很多公司都有做，阿里的 DRC 也是。
            - 主要依赖于 MySQL 的 binlog（TODO：了解一下）
                binlog 设置成 row 格式的情况下，会将所有受影响的数据都记录到日志中，就提供了所有数据的变化
            - 通过解析 row 格式的 MySQL binlog 将数据变化读取到 databus，将实际需要的业务逻辑进行处理，
                `*.so` 文件 load 到 databus 中，databus 根据业务逻辑重新处理一下数据的变化，然后输出
            - 项目已开源 github/MyBus
        - 「索引」指的是，找到对应内容的算法是？
            「索引」：存储（微博）博文，需要存储 id（mid），还有发博文的状态，谁发的，发的时间，都算索引。
            由于博文内容较大，索引不会和内容存储在一起（避免 MySQL 性能下降），
            所以通常拿到博文 id 就算是拿到了实际的博文。
        - NoSQL 发挥的作用
            例如 rediscounter，自研的计数服务。
            - 一开始计数存在 MySQL 中，都用 update set count = count + 1，
                高并发对单行数据的写操作，会导致多种锁，并发越高被锁得越厉害。
            - （看原文原图）MySQL 对单行数据的并发操作达到 500+，tps 就会从 1w+ 变成几百，
                所以无论怎么优化 MySQL 也无法适应这种场景。但是 Redis 可以。
                （这里没有展开，据说用线性拟合做计数，后期又要改成精确计数）
        - 哪些信息存在 MySQL？哪些存 NoSQL？用什么 NoSQL 方案？
            分层存储：MySQL + Redis + MC
            - Redis + MC 扛热点（数据）和峰值，MySQL 用于数据落地（持久存储），保障最终有原始数据可查。
                大部分请求会到 MC 或 Redis 就返回了，只有 1% 的数据会落到 MySQL 上。
            - 特殊场景：rediscounter 计数服务，直接用它存，并没有再用 MySQL 存一份数据。
            - NoSQL 优势：开发便捷，因为是 k-v 结构，所有查询都是「主键查询」，
                不用考虑 index（索引）优化的问题，不用考虑如何建表。
        - 全局唯一发号器，自动生成 id 对业务的优劣分别是？
            - 全局唯一发号器，实现方案很多，微博用 mc 协议改 Redis 实现的，主要追求性能。
                也有用 MySQL 的自增 id 作为发号器，但由于 MySQL 锁太重，高并发场景下不好用。
            - 其实全局唯一发号器的开发难度并不高，可以将想要的属性封装到 uuid 中，
                例如，时间戳 + 业务号 + 自增序列数，那么拿到 id 时，就能知道业务，
                比起 MySQL 生成的没意义的序列号，其实可能更好用

## 支撑微博迁移调用的轻量级 RPC 框架 Motan

- 主讲：张雷，新浪微博技术专家，MotanRPC 框架技术负责人。
    TODO
